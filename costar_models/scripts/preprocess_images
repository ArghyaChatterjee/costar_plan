#!/usr/bin/env python

from __future__ import print_function

from scipy.misc import imresize

import argparse
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
import sys
import h5py

from costar_models import *
from costar_models.planner import GetOrderedList, PrintTopQ
from costar_models.sampler2 import PredictionSampler2
from costar_models.datasets.npz import NpzDataset
from costar_models.datasets.h5f import H5fDataset
from costar_models.datasets.npy_generator import NpzGeneratorDataset
from costar_models.datasets.h5f_generator import H5fGeneratorDataset

from costar_models.planner import *
from costar_models.multi import *
from costar_models.dvrk import MakeJigsawsImageClassifier

from costar_models.datasets.image import GetJpeg, JpegToNumpy

def convertJpegToImages(features):
    for i, f in enumerate(features):
        if str(f.dtype)[:2] == "|S":
            f = ConvertJpegListToNumpy(np.squeeze(f))
            features[i] = f
    return features

def main(args):
    '''
    Tool for running model training without the rest of the simulation/planning/ROS
    code. This should be more or less independent and only rely on a couple
    external features.
    '''
    ConfigureGPU(args)

    np.random.seed(0)
    data_file_info = args['data_file'].split('.')
    data_type = data_file_info[-1]
    new_data_file = "small_" + data_file_info[0]
    root = ""
    for i, tok in enumerate(data_file_info[:-1]):
        if i < len(data_file_info)-1 and i > 0:
            root += '.'
        root += tok
    if data_type == "npz":
        dataset = NpzGeneratorDataset(root)
        data = dataset.load(success_only = args['success_only'])
    elif data_type == "h5f":
        dataset = H5fGeneratorDataset(root)
        data = dataset.load(success_only = args['success_only'])
    else:
        raise NotImplementedError('data type not implemented: %s'%data_type)

    if 'features' not in args or args['features'] is None:
        raise RuntimeError('Must provide features specification')
    features_arg = args['features']

    if 'model' not in args or args['model'] is None:
        raise RuntimeError('Must provide a model to load')
    model_arg = args['model']

    for fnum, filename in enumerate(dataset.test + dataset.train):
        newdata = {}
        data = dataset.loadFile(filename)
        for k, v in data.items():
            if not k == "images":
                newdata[k] = v
            for i in range(0):
                crop = frame
                image = imresize(crop, (96, 96))
                image = image.astype(np.uint8)
                plt.figure()
                plt.imshow(image)
                plt.show()


def write(directory, filename, data):
    filename = os.path.join(directory, filename)
    f = h5py.File(filename, 'w')
    for key, value in data.items():
        f.create_dataset(key, data=value)
    f.close()


info = """
This script will preprocess images collected from the real robot (with the 
CoSTAR setup), shrink them, crop slightly, and save as a new set of h5f files.
When specifying the data set, the name "small_" will be appended to the
beginning. Example usage:\n
\tpreprocess_images --data_file robot.h5f --features costar\n
This will write to:\n
\t./small_robot\n
which will contain a set of h5f files. Specifically, this code will enforce the
following changes:\n
\timage: resized, handled as jpeg
\tdepth: TODO
"""

if __name__ == '__main__':
    print(info)
    args = ParseModelArgs()
    if args['profile']:
        import cProfile
        cProfile.run('main(args)')
    else:
        main(args)
